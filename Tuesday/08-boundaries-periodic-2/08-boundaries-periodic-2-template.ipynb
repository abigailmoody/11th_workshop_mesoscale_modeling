{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d5c574-1196-45bb-982c-c9ff28f88f60",
   "metadata": {},
   "source": [
    "# Periodic Boundary Conditions - Dynamics \n",
    "\n",
    "## Overview\n",
    "\n",
    "In this session, we will learn how to compute dynamical quantities from an MD simulation. \n",
    "\n",
    "### Questions\n",
    "\n",
    "- How do I compute dynamic quantities like the diffusion coefficient from a MD simulation?\n",
    "\n",
    "### Objectives\n",
    "\n",
    "- Calculate the mean-squared displacement of monomers, monomers relative to the center of mass of a polymer, and the center of mass MSD of a polymer.\n",
    "- Extract the average diffusion coefficent from the measured MSD for a simple polymer model.\n",
    "- Show that the simple polymer model agrees with scaling expectations (Rouse model).\n",
    "\n",
    "## Boilerplate code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a1ce94-0547-4654-800a-a6cb20c03d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy\n",
    "import scipy.stats\n",
    "import gsd, gsd.hoomd\n",
    "import freud\n",
    "import math\n",
    "import itertools\n",
    "import hoomd\n",
    "import fresnel\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.style.use(\"ggplot\")\n",
    "import matplotlib_inline\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")\n",
    "\n",
    "def render(frame):\n",
    "    scene = fresnel.Scene()\n",
    "    geometry = fresnel.geometry.Sphere(scene, N=frame.particles.N)\n",
    "    geometry.material = fresnel.material.Material(color=fresnel.color.linear([0.01, 0.74, 0.26]), roughness=0.5)\n",
    "    geometry.position[:] = frame.particles.position\n",
    "    geometry.outline_width = 0.01\n",
    "    box = fresnel.geometry.Box(scene, frame.configuration.box,box_radius=0.01)\n",
    "    L = frame.configuration.box[0]\n",
    "    scene.camera = fresnel.camera.Perspective(position=(L*1.8, L*1.8, L * 2.2), look_at=(0, 0, 0), up=(0, 1, 0), height=0.28)\n",
    "\n",
    "    if frame.bonds.N>0:\n",
    "        geometry.radius[:] = [0.2]*frame.particles.N\n",
    "\n",
    "        all_bonds = numpy.stack(\n",
    "        [\n",
    "            frame.particles.position[frame.bonds.group[:, 0]],\n",
    "            frame.particles.position[frame.bonds.group[:, 1]],\n",
    "        ],\n",
    "        axis=1,\n",
    "        )\n",
    "        # Use a distance cutoff (L/2) to filter bonds that span the periodic boundary\n",
    "        bond_distances = numpy.linalg.norm(all_bonds[:,0,:]-all_bonds[:,1,:], axis=1)\n",
    "        L = frame.configuration.box[0]\n",
    "        bond_indices = numpy.where(bond_distances < L/2)[0]\n",
    "        filtered_bonds = all_bonds[bond_indices, :, :]\n",
    "\n",
    "        bonds = fresnel.geometry.Cylinder(scene, N=len(filtered_bonds))\n",
    "        bonds.material = fresnel.material.Material(roughness=0.5)\n",
    "        bonds.outline_width = 0.05\n",
    "\n",
    "        bonds.points[:] = filtered_bonds\n",
    "        bonds.radius[:] = [0.1]*len(filtered_bonds)\n",
    "        bonds.material.primitive_color_mix = 1.0\n",
    "        bonds.color[:] = fresnel.color.linear([0.8, 0.8, 0.8])\n",
    "\n",
    "    return fresnel.preview(scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36c6932-3055-4d09-b307-f99c6cf3c8c6",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "We will largely follow [Mussawisade, K., M. Ripoll, R. G. Winkler, and G. Gompper. \"Dynamics of polymers in a particle-based mesoscopic solvent.\" The Journal of chemical physics 123, no. 14 (2005)](http://doi.org/10.1063/1.2041527) for our model/parameter choices. In this section, we will implement and run a Gaussian Chain simulation with no pair interactions. This will model a so-called \"ideal polymer\".\n",
    "\n",
    "## Simulation \n",
    "\n",
    "### Initial Snapshot \n",
    "\n",
    "Write a function that initializes `num_pol` with length `num_mon` each. Initialize them as straight rods inside the box. Feel free to ajust the box size to be large enough to fit the polymers.\n",
    "\n",
    "Hints:\n",
    "1. Use `numpy.linspace` to make an array going from `-mon_num/2` to `mun_nom/2+1`. How many steps do you need to make a polymer of length `num_mon`?\n",
    "2. then use `numpy.hstack` to create a position array of the correct shape. What *is* the correct shape? You can always print the shape of an numpy array by using `print(array.shape)` and check your work! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e221ef9-c931-4594-80ec-261f2f387a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_snapshot(num_pol,num_mon):\n",
    "\n",
    "    position_x = numpy.linspace(...)\n",
    "    position = numpy.hstack((...))\n",
    "    positions = []\n",
    "    for i in range(num_pol):\n",
    "        # offset to shift current polymer number i a little off its neighbors\n",
    "        offset = [0,-num_mon/2+i*1.1,0]\n",
    "        positions.append(position + offset)\n",
    "\n",
    "    positions = numpy.asarray(positions).reshape(-1,3)\n",
    "\n",
    "    bonds = numpy.vstack((numpy.arange(num_pol*num_mon-1),numpy.arange(1,num_pol*num_mon))).T\n",
    "    bonds = bonds[bonds[:,1] % num_mon !=0 ]\n",
    "\n",
    "    frame = gsd.hoomd.Frame()\n",
    "    frame.particles.types = ['A']\n",
    "    frame.particles.N = ...\n",
    "    frame.particles.position = ...\n",
    "    frame.bonds.N = ...\n",
    "    frame.bonds.group = ...\n",
    "    frame.bonds.types = ['b']\n",
    "    L = 2*numpy.max(numpy.abs(position))\n",
    "    frame.configuration.box = [L, L, L, 0, 0, 0]\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d64b2c5-764f-4ccb-848e-b04b0709045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = initialize_snapshot(10,20)\n",
    "render(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833f7bdc-3687-484e-9b07-fa197f7ca3b4",
   "metadata": {},
   "source": [
    "This is one simple way to set up a initial configuration. For any actual workflow, it might be worthwile to improve this initial snapshot setup to get closer to a correct configuration, i.e for example one could implement a random walk or a self avoiding random walk. \n",
    "\n",
    "## Simulation Setup \n",
    "\n",
    "The `num_mon` monomers in a Guassian chain are connected to form a polymer of length `mum_mon` by a *harmonic* bond potential. The spring constant is $\\frac{3 k_{B} T}{2 b^{2}}$ and  with zero mean bond length. Here, $b$ is the root-mean-square bond length and $k_BT$ is the temperature. We rename the the root-mean-square bond length variable to $b$ (from $l$ used in the original paper) to avoid conflict with variable names used later.\n",
    "*Note* that the factor of $1/2$ is already in hoomd-blue's definition of the [harmonic bond potential](https://hoomd-blue.readthedocs.io/en/stable/hoomd/md/bond/harmonic.html). \n",
    "\n",
    "Since the chains are non-interacting, i.e., they have no excluded volume, we might as well put some number of polymers, `num_pol`, into the simulation box to improve the statistics of the measurnments done later. If the chains were interacting, we would need to think about the effects of polymer concentrations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b22b4f-286b-4509-8923-f724ddc71646",
   "metadata": {},
   "outputs": [],
   "source": [
    "kT = 1.0\n",
    "l = 1.0\n",
    "harmonic = hoomd.md.bond.Harmonic()\n",
    "harmonic.params[\"b\"] = dict(r0=0, k=3*kT/l**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852efe16-6072-4bf5-9afc-5035ac7f956d",
   "metadata": {},
   "source": [
    "Now we can set up the rest of the simulation exactly like we have done for previous Langevin simulations.\n",
    "\n",
    "**Note** that we write the images into the GSD files here by using `dynamic` keyword with both `property` and `momentum`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba56b44a-cf91-4a4d-ac6d-629c160f90d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 0.01\n",
    "gamma = 0.1\n",
    "\n",
    "num_pol = 10\n",
    "num_mon = 80\n",
    "\n",
    "frame = initialize_snapshot(num_pol,num_mon)\n",
    "\n",
    "# add code\n",
    "integator = ...\n",
    "\n",
    "integrator.forces.append(harmonic)\n",
    "\n",
    "# add code\n",
    "simulation = ...\n",
    "simulation.operations.integrator = ...\n",
    "simulation.create_state_from_snapshot(...)\n",
    "\n",
    "# Equilibrate\n",
    "simulation.run(100_000)\n",
    "\n",
    "gsd_out = hoomd.write.GSD(\n",
    "    trigger=hoomd.trigger.Periodic(1_000),\n",
    "    mode='wb',\n",
    "    dynamic=['property','momentum'],\n",
    "    filename='run_len_%s_pol_%s.gsd'%(num_mon,num_pol))\n",
    "\n",
    "simulation.operations.writers.append(gsd_out)\n",
    "# run\n",
    "simulation.run(5_000_000)\n",
    "\n",
    "gsd_out.flush()\n",
    "render(simulation.state.get_snapshot())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b0844c-8075-4fa2-a58e-37daf2965e76",
   "metadata": {},
   "source": [
    "While the simulation is running, look up what the scaling relationship for the [diffusion coefficent](https://en.wikipedia.org/wiki/Rouse_model) is expected to be for a simple polymer model without excluded volume interactions or hydrodynamics. Look up the **Rouse** and the **Zimm** model. \n",
    "\n",
    "To check if our simulation has run properly, we can check the bond lengths. The bond length distribution should follow a Gaussian distribution (as the name of the model implies). \n",
    "\n",
    "Hints: \n",
    "1. We can use `numpy.linalg.norm()` to compute the length of a vector. What axis to we need to indicate? Hint: check the shapes of your arrays.\n",
    "2. Compute the bond vector by using the unwrapped positions. Rember that the first index in each bond is given by `frame.bonds.group[:, 0]` and the second one is `frame.bonds.group[:, 1]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9f8aed-c8e4-41bc-9e24-e74bbfff735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory =  gsd.hoomd.open('run_len_80_pol_10.gsd','r')\n",
    "\n",
    "all_bonds = []\n",
    "for frame in trajectory:\n",
    "    # add code - this is the same as we have done for the Rg exercise!\n",
    "    unwrapped_positions = ...\n",
    "    bond_vectors =\n",
    "    bonds_lengths =  ...\n",
    "    all_bonds.append(bonds_lengths)\n",
    "\n",
    "fig,ax = matplotlib.pyplot.subplots(1,1)\n",
    "\n",
    "hist , edges = numpy.histogram(...)\n",
    "\n",
    "# add code to calculate the centers of each bin\n",
    "center = ...\n",
    "ax.plot(center,hist)\n",
    "ax.set_xlabel(\"bond length\")\n",
    "ax.set_ylabel(\"count\")\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cbf319-132e-44f2-b6ca-4a802f81b421",
   "metadata": {},
   "source": [
    "## Analyze MSD \n",
    "\n",
    "To analyze the MSD, we will write a function that takes a filename for gsd trajectory, opens the trajectory and computes the MSD using [freud](https://freud.readthedocs.io/en/latest/modules/msd.html). We will compute the monomer MSD ($g_1$), the relative monomer to center of mass MSD ($g_2$), and the center of mass MSD ($g_3$). We expect both the monomer and the com MSD to eventually scale linearly with time, $MSD \\sim t^1$. The relative monomer to center of mass diffusion will plateau out at long times. \n",
    "\n",
    "**Write a function that calculates all three MSDs.**\n",
    "\n",
    "You will need to iterate over the trajectory, find a way to separate the positions for the different polymers (see last lecture!), calculate the center of mass of each polymer, and then save the unwrapped positions, center of mass, and the unwrapped positions relative (minus) the center of masses in arrays of appropriate shape. \n",
    "\n",
    "Note that we want to substract a *global* center of mass drift, i.e entire simulation drift. This drift should be minimal if the thermostat is working correctly. Especially for systems with only a few particles, there still can be some effect, simply because there are not enough velocities to ensure that the mean of all velocities is exactly zero. In any case, it does not hurt to substract the global center of mass from the positions once they are unwrapped. \n",
    "\n",
    "Once you have three arrays, one with unwrapped positions `all_unwrapped_positions`, one with relative unwraped positions `all_unwrapped_coms_particles`, and one with center of masses `all_unwrapped_coms`, we can use freud to compute the MSD in the next step. \n",
    "\n",
    "Hints: \n",
    "1. When we compute these arrays, feel free to print out their shapes at various steps to debug. \n",
    "2. We need to use `numpy.repeat` to adjust the size of the `unwrapped_coms` and the `unwrapped_positions` array to be able to substract them from each other. `numpy.repeat` will take an array `[1,2,3,..]` and turn it into `[1,1,1,..2,2,2,..,3,3,3,..]`. How often do we need to repeat and over which axis? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849a039a-094e-4d54-a686-df3aecb7db29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_msd(filename,timestep):\n",
    "    trajectory =  gsd.hoomd.open(filename,'r')\n",
    "\n",
    "    all_unwrapped_positions = []\n",
    "    all_unwrapped_coms = []\n",
    "    all_unwrapped_coms_particles = []\n",
    "    times = []\n",
    "\n",
    "    # Hint: this is the same as for the Rg exercise!\n",
    "    box  = ...\n",
    "    bonds = ...\n",
    "    polymer_delimiters = ...\n",
    "    time0 = trajectory[0].configuration.step\n",
    "    for frame in trajectory:\n",
    "\n",
    "        # unwrap by adding frame*box to the positions:\n",
    "        unwrapped_positions = ...\n",
    "        # substract global com\n",
    "        unwrapped_positions = unwrapped_positions -numpy.mean(unwrapped_positions,axis=0)\n",
    "        all_unwrapped_positions.append(...)\n",
    "\n",
    "        # split polymers, calculate com for each, append to proper arrays\n",
    "        polymers = numpy.split(...)\n",
    "        unwrapped_coms = []\n",
    "        for p in polymers:\n",
    "            com = numpy.mean(...)\n",
    "            unwrapped_coms.append(com)\n",
    "\n",
    "        # currently our com array and our particles (unwrapped positions) array have very different shapes.\n",
    "        # we need to fix that so we can substract them to compute positions - com.\n",
    "        unwrapped_coms_tiled = numpy.repeat(...)\n",
    "        diff = unwrapped_positions - unwrapped_coms_tiled\n",
    "        all_unwrapped_coms_particles.append(diff)\n",
    "\n",
    "        all_unwrapped_coms.append(...)\n",
    "        times.append(frame.configuration.step-time0)\n",
    "\n",
    "    all_unwrapped_positions = numpy.array(all_unwrapped_positions)  # shape = (nframes,nparticles,3)\n",
    "    all_unwrapped_coms = numpy.array(all_unwrapped_coms)            # shape = (nframes,npolymers,3)\n",
    "    all_unwrapped_coms_particles = numpy.array(all_unwrapped_coms_particles)  # shape = (nframes,nparticles,3)\n",
    "\n",
    "    # add MSD msd1 calcuation using freud\n",
    "\n",
    "    msd_calculator = freud.msd.MSD()\n",
    "    # put postions here\n",
    "    msd_calculator.compute(...)\n",
    "    # average MSD over all particles (or com, depending)\n",
    "    result = msd_calculator.particle_msd\n",
    "    msd1 = numpy.nanmean(result,axis=1)\n",
    "\n",
    "    # repeat code above to comute msd2 and msd3\n",
    "    ...\n",
    "\n",
    "\n",
    "    lagtimes = numpy.asarray(times)*timestep\n",
    "\n",
    "    return lagtimes, msd1, msd2, msd3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410f2b93-bfe0-416e-a8aa-f9fee0f2f041",
   "metadata": {},
   "source": [
    "Now we can plot our results for one chain length, let's say $N=80$ and check against our expectations. We will also take the derivative `numpy.gradient` to compute $D(t)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4238e86e-47dd-4ae0-bb2e-f11e2c449b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = matplotlib.pyplot.subplots(2,1)\n",
    "\n",
    "# plot the 3 msds in one panel, and D(t) in the second panel.\n",
    "lagtimes, msd1, msd2, msd3 = analyze_msd(\"run_len_80_pol_10.gsd\",0.01)\n",
    "\n",
    "ax[0].plot(lagtimes, msd1,label='g1 = monomer msd')\n",
    "ax[0].plot(lagtimes, msd2,label='g2 = monomer-com msd')\n",
    "ax[0].plot(lagtimes, msd3,label='g3 = com msd')\n",
    "\n",
    "gradient = numpy.gradient(msd3, lagtimes)\n",
    "ax[1].plot(lagtimes,gradient/(6.0),label='D(t)=1/6 d/dt g3')\n",
    "\n",
    "\n",
    "ax[0].set_ylabel(\"$MSD$\")\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "ax[1].set_xlabel(r\"$time$\")\n",
    "ax[1].set_ylabel(\"$D$\")\n",
    "\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a55a43-ec53-401e-bb7f-60f7a4cf5c40",
   "metadata": {},
   "source": [
    "Now, repeat the simulation we have done above for a few values of $N$ in the range of 20 to 80. Keep the number of polymers `num_pol` constant at 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf32d88b-06f0-4298-ab59-21fb53281ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy code from above OR modify the code above to change chain length\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a455de5-8434-4b66-9c13-65d66d52b0ee",
   "metadata": {},
   "source": [
    "After that, let's determine the $MSD$, $D(t)$ and $\\langle D\\rangle$ of each chain length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a097ecb-3591-407c-b16c-ad54952e2cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = matplotlib.pyplot.subplots(2,1)\n",
    "\n",
    "# we will take the average of D(t) only in the range over which it appears to be constant\n",
    "fit_range = [10,30000]\n",
    "\n",
    "# add your chain lengths\n",
    "Ns = [....]\n",
    "all_av_D = []\n",
    "\n",
    "for N in Ns:\n",
    "    lagtimes, msd1, msd2, msd3 = analyze_msd(...)\n",
    "    D = numpy.gradient(...)/...\n",
    "    ax[0].plot(lagtimes, msd3,label='N=%s'%N)\n",
    "    ax[1].plot(lagtimes,D)\n",
    "    diffusion_coefficient = numpy.mean(D[(lagtimes>fit_range[0]) & (lagtimes<fit_range[1])])\n",
    "\n",
    "    all_av_D.append(diffusion_coefficient)\n",
    "\n",
    "# plot results\n",
    "ax[0].set_ylabel(\"$MSD$\")\n",
    "ax[0].set_yscale('log')\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].legend()\n",
    "# adjust if needed\n",
    "ax[1].set_ylim(-0.05,0.2)\n",
    "ax[1].set_xlabel(r\"$time$\")\n",
    "ax[1].set_ylabel(\"$D$\")\n",
    "\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c30ce21-c34f-4bb7-9169-b2bb52b71dfd",
   "metadata": {},
   "source": [
    "For comparison, load the file `gaussian-D-Rg.txt`, which contains calculated diffusion coefficents (and $R_g$ in column 3) for $N=10$ to $100$ and plot your data with those diffusion coefficients. Do they follow the expected scaling law? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a53557d-e074-4db2-86d4-6da9b11b40ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = matplotlib.pyplot.subplots(1,1)\n",
    "\n",
    "x = numpy.arange(10,100,1)\n",
    "# load file\n",
    "data = numpy.genfromtxt(\"gaussian-D-Rg.txt\")\n",
    "# add scaling fit\n",
    "ax.plot(x,...,c='blue')\n",
    "ax.scatter(data[:,0], data[:,1])\n",
    "ax.scatter(Ns, all_av_D)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel(r\"$N$\")\n",
    "ax.set_ylabel(r\"$\\langle D \\rangle$\")\n",
    "matplotlib.pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6ddb93-4b47-4f21-a5ab-47946c9d8daf",
   "metadata": {},
   "source": [
    "## Additions \n",
    "\n",
    "1. How would you decide on the `fit_range` for the diffusion coefficient? *Hint:* Is there a way to estimate the uncertainty of $D(t)$?\n",
    "2. What happens if we add pair interactions to our simulation? What solvent qualities can we model? Do the results still agree with the Rouse model expectations?\n",
    "3. What happens if we change the temperature `kT`$=k_{\\mathrm {B}}T$ or the friction coefficient `gamma` in our simulations? Do the results still agree with the Rouse model expectations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f432ecf-a31b-49d9-89d2-0de529d44690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
